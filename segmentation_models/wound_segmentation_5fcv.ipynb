{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required libs\n",
    "#!pip install -U segmentation-models-pytorch albumentations --user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import path\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root dir\n",
    "PATH_ROOT = 'root_dir'\n",
    "\n",
    "# dataset\n",
    "DATASET = 'dataset_name'\n",
    "\n",
    "# cv dirs\n",
    "PATH_FOLDS = path.join(PATH_ROOT, 'datasets/enriched/', DATASET, 'scv_train/{}/')\n",
    "PATH_TRAIN_IMAGES = path.join(PATH_FOLDS, 'train/images/')\n",
    "PATH_TRAIN_LABELS = path.join(PATH_FOLDS, 'train/labels/')\n",
    "PATH_VAL_IMAGES = path.join(PATH_FOLDS, 'val/images/')\n",
    "PATH_VAL_LABELS = path.join(PATH_FOLDS, 'val/labels/')\n",
    "\n",
    "# folds\n",
    "FOLDS = 5\n",
    "\n",
    "# single fold processing\n",
    "FOLDS_TO_PROCESS = [1,2,3,4,5] # None\n",
    "\n",
    "print(PATH_FOLDS)\n",
    "for f in range(1, FOLDS+1):\n",
    "    n_ti = len(os.listdir(PATH_TRAIN_IMAGES.format(f)))\n",
    "    n_tl = len(os.listdir(PATH_TRAIN_LABELS.format(f)))\n",
    "    n_vi = len(os.listdir(PATH_VAL_IMAGES.format(f)))\n",
    "    n_vl = len(os.listdir(PATH_VAL_LABELS.format(f)))\n",
    "    print('fold ', f, ':\\t\\t', 'train ', n_ti, '/', n_tl, '; val ', n_vi, '/', n_vl, sep='')\n",
    "\n",
    "if FOLDS_TO_PROCESS != None:\n",
    "    print('subset of folds will be processed:', FOLDS_TO_PROCESS)\n",
    "else:\n",
    "    print('all folds will be processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes/intensities\n",
    "CLASSES = [\n",
    "    'background',\n",
    "    'wound'\n",
    "]\n",
    "\n",
    "for i in range(len(CLASSES)):\n",
    "    print('value ', i, ':\\t', CLASSES[i], sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "def visualize(**images):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# non-keyworded images: image1, image2, ...\n",
    "def visualize_grid(*images):\n",
    "    n, cols = len(images), 4\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    gs = gridspec.GridSpec(rows, cols)\n",
    "    fig = plt.figure(figsize=(16, 4*rows))\n",
    "    fig.tight_layout()\n",
    "    for i in range(n):\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        ax.imshow(images[i])\n",
    "        ax.axis('off')    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "    \n",
    "    CLASSES = ['background', 'wound']\n",
    "    \n",
    "    def __init__(self, images_dir, masks_dir, classes=None, augmentation=None, preprocessing=None):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv.imread(self.images_fps[i])\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        mask = cv.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check fold sample\n",
    "fold = Dataset(PATH_TRAIN_IMAGES.format(1), PATH_TRAIN_LABELS.format(1), classes=['wound'])\n",
    "image, mask = fold[3100]\n",
    "visualize(image=image, ground_truth=mask.squeeze())\n",
    "\n",
    "# save image height/width\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, _ = image.shape\n",
    "assert (IMAGE_HEIGHT % 32) + (IMAGE_WIDTH % 32) == 0, 'image height/width must be divisible by 32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION = 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        \n",
    "        # random crop (basic)\n",
    "        albu.RandomCrop(\n",
    "            height=352,\n",
    "            width=352,\n",
    "            always_apply=True\n",
    "        ),\n",
    "        \n",
    "        # geometry (basic)\n",
    "        albu.Flip(p=0.5),\n",
    "        albu.ShiftScaleRotate(p=0.5),\n",
    "        \n",
    "        # distortion, shuffling (heavy)\n",
    "        albu.OneOf([\n",
    "            albu.GridDistortion(p=1),            \n",
    "            albu.ElasticTransform(p=1),\n",
    "        ], p=0.5),      \n",
    "        \n",
    "        # contrast, brightness (basic)\n",
    "        albu.OneOf([\n",
    "            albu.CLAHE(p=1),\n",
    "            albu.RandomGamma(p=1),\n",
    "            albu.RandomBrightnessContrast(p=1),\n",
    "        ], p=0.5),\n",
    "\n",
    "        # blurring, sharpening (basic)\n",
    "        albu.OneOf([\n",
    "            albu.Sharpen(p=1),\n",
    "            albu.Blur(blur_limit=8, p=1),\n",
    "            albu.MotionBlur(blur_limit=8, p=1),\n",
    "        ], p=0.5),      \n",
    "        \n",
    "        # noise (basic)\n",
    "        albu.OneOf([\n",
    "            albu.GaussNoise(p=1),\n",
    "        ], p=0.5),\n",
    "                \n",
    "    ]\n",
    "    \n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    val_transform = [albu.PadIfNeeded(IMAGE_HEIGHT, IMAGE_WIDTH)]    \n",
    "    return albu.Compose(val_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):    \n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):    \n",
    "    _transform = [albu.Lambda(image=preprocessing_fn), albu.Lambda(image=to_tensor, mask=to_tensor)]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset with augmentation pipeline for training\n",
    "dataset = Dataset(\n",
    "    PATH_TRAIN_IMAGES.format(f), PATH_TRAIN_LABELS.format(f), \n",
    "    classes=CLASSES, augmentation=get_training_augmentation(),\n",
    ")\n",
    "\n",
    "# visualize exemplary sample augmentations\n",
    "visualize_grid(*[dataset[1234][0] for _ in range(16)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "MODEL = 'fpn' # TODO: currently hard-coded, fix\n",
    "ENCODER = 'se_resnext101_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda'\n",
    "CLASSES = ['wound'] # ['background', 'wound']\n",
    "\n",
    "# training parameters\n",
    "OPTIMIZER = 'adam' # TODO: currently hard-coded, fix\n",
    "LR_INIT = 0.0001\n",
    "LR_DROP = None #0.00005 # 0.00001\n",
    "\n",
    "# batch size, epochs \n",
    "BATCH_SIZE = 24\n",
    "EPOCHS = 300\n",
    "EPOCHS_DROP = None # LR_DROP after stated epoch (e.g., 25 -> reduced LR from epoch 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run dir\n",
    "PATH_RUNS = path.join(PATH_ROOT, 'models/')\n",
    "\n",
    "# run name\n",
    "if LR_DROP == None and EPOCHS_DROP == None:\n",
    "    # no lr adjustments\n",
    "    RUN_NAME = 'crossval__{}__{}_{}_{}_{}__{}_lr{:.0e}__{}__bs{}_e{}'.format(\n",
    "        DATASET, MODEL, ENCODER, ENCODER_WEIGHTS, ACTIVATION, \n",
    "        OPTIMIZER, LR_INIT, AUGMENTATION, BATCH_SIZE, EPOCHS,\n",
    "    )\n",
    "else:\n",
    "    # lr adjustments\n",
    "    RUN_NAME = 'crossval__{}__{}_{}_{}_{}__{}_lr{:.0e}_lrd{:.0e}__{}__bs{}_e{}_ed{}'.format(\n",
    "        DATASET, MODEL, ENCODER, ENCODER_WEIGHTS, ACTIVATION, \n",
    "        OPTIMIZER, LR_INIT, LR_DROP, AUGMENTATION, BATCH_SIZE, EPOCHS, EPOCHS_DROP\n",
    "    )\n",
    "print('dir:\\t', PATH_RUNS)\n",
    "print('run:\\t', RUN_NAME)\n",
    "print('path:\\t', path.join(PATH_RUNS, RUN_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create dirs\n",
    "PATH_RUN = path.join(PATH_RUNS, RUN_NAME)\n",
    "PATH_LOG = path.join(PATH_RUN, 'log')\n",
    "if not path.isdir(PATH_LOG):\n",
    "    os.makedirs(PATH_LOG)\n",
    "\n",
    "folds = range(1, FOLDS+1)\n",
    "if FOLDS_TO_PROCESS != None:\n",
    "    folds = FOLDS_TO_PROCESS\n",
    "\n",
    "# perform individual training for any fold\n",
    "print('{}-fold cross-validation: Started'.format(FOLDS))\n",
    "cv_start = time.time()\n",
    "txt_log = list()\n",
    "for fold in folds:\n",
    "       \n",
    "    print('\\n', '-'*80, sep='')\n",
    "    print('\\n', 'Fold {} training: Started'.format(fold))\n",
    "    fold_start = time.time()\n",
    "    \n",
    "    # tensorboard log for fold\n",
    "    tb_log = SummaryWriter(log_dir=os.path.join(PATH_LOG, 'fold{}'.format(fold)))\n",
    "    \n",
    "    ### MODEL\n",
    "    # create segmentation model with pretrained encoder\n",
    "    model = smp.FPN(\n",
    "        encoder_name=ENCODER, encoder_weights=ENCODER_WEIGHTS,\n",
    "        classes=len(CLASSES), activation=ACTIVATION\n",
    "    )\n",
    "    preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "    \n",
    "    ### DATASETS, LOADERS\n",
    "    # create training and validation datasets and loaders\n",
    "    train_dataset = Dataset(\n",
    "        PATH_TRAIN_IMAGES.format(fold), PATH_TRAIN_LABELS.format(fold), # fold set here\n",
    "        augmentation=get_training_augmentation(), preprocessing=get_preprocessing(preprocessing_fn),\n",
    "        classes=CLASSES,\n",
    "    )\n",
    "    val_dataset = Dataset(\n",
    "        PATH_VAL_IMAGES.format(fold), PATH_VAL_LABELS.format(fold), # fold set here\n",
    "        augmentation=get_validation_augmentation(), preprocessing=get_preprocessing(preprocessing_fn),\n",
    "        classes=CLASSES,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16, prefetch_factor=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "    \n",
    "\n",
    "    ### LOSS, SCORE, OPTIMIZER\n",
    "    # create loss, score, and optimizer\n",
    "    loss = smp.utils.losses.DiceLoss() # Dice/F1 loss\n",
    "    metrics = [\n",
    "        smp.utils.metrics.Fscore(threshold=0.5), # Dice/F1 Score\n",
    "        smp.utils.metrics.IoU(threshold=0.5), # Jaccard/IoU score\n",
    "    ] \n",
    "    optimizer = torch.optim.Adam([dict(params=model.parameters(), lr=LR_INIT)])\n",
    "\n",
    "    \n",
    "    ### RUNNERS\n",
    "    # create epoch runners (loop of iterating over dataloader's samples)\n",
    "    train_epoch = smp.utils.train.TrainEpoch(\n",
    "        model, loss=loss, metrics=metrics, \n",
    "        optimizer=optimizer, device=DEVICE, verbose=True\n",
    "    )\n",
    "    val_epoch = smp.utils.train.ValidEpoch(\n",
    "        model, loss=loss, metrics=metrics, \n",
    "        device=DEVICE, verbose=True\n",
    "    )\n",
    "    \n",
    "\n",
    "    ### TRAINING\n",
    "    # train model\n",
    "    max_score_dice = 0\n",
    "    max_score_jaccard = 0\n",
    "    best_epoch_dice = 0\n",
    "    best_epoch_jaccard = 0\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        \n",
    "        \n",
    "        # run epoch\n",
    "        print('\\nEpoch: {}'.format(epoch))        \n",
    "        train_logs = train_epoch.run(train_loader)\n",
    "        val_logs = val_epoch.run(val_loader)\n",
    "        \n",
    "\n",
    "        ### LOGGING\n",
    "        # dice/f1 loss\n",
    "        tb_log.add_scalar('train/Dice loss (F1)', train_logs['dice_loss'], epoch)\n",
    "        tb_log.add_scalar('val/Dice loss (F1)', val_logs['dice_loss'], epoch)\n",
    "                \n",
    "        # dice/f1 score\n",
    "        tb_log.add_scalar(\"train/Dice score (F1)\", train_logs['fscore'], epoch)\n",
    "        tb_log.add_scalar(\"val/Dice score (F1)\", val_logs['fscore'], epoch)\n",
    "        \n",
    "        # jaccard/iou score\n",
    "        tb_log.add_scalar('train/Jaccard index (IoU)', train_logs['iou_score'], epoch)\n",
    "        tb_log.add_scalar('val/Jaccard index (IoU)', val_logs['iou_score'], epoch)\n",
    "        \n",
    "        txt_log.append({\n",
    "            'fold': fold, 'epoch': epoch, \n",
    "            'dice_loss': val_logs['dice_loss'],\n",
    "            'fscore': val_logs['fscore'],\n",
    "            'iou_score': val_logs['iou_score'],\n",
    "        })\n",
    "        \n",
    "        \n",
    "        ### EVALUATION\n",
    "        # save epoch if better dice/f1\n",
    "        if max_score_dice < val_logs['fscore']:\n",
    "            max_score_dice = val_logs['fscore']\n",
    "            best_epoch_dice = epoch\n",
    "            torch.save(model, path.join(PATH_RUN, './best_model_dice_fold{}.pth'.format(fold)))\n",
    "            print('Model saved (best Dice score (F1))')\n",
    "        \n",
    "        # save epoch if better jaccard/iou\n",
    "        if max_score_jaccard < val_logs['iou_score']:\n",
    "            max_score_jaccard = val_logs['iou_score']\n",
    "            best_epoch_jaccard = epoch\n",
    "            torch.save(model, path.join(PATH_RUN, './best_model_jaccard_fold{}.pth'.format(fold)))\n",
    "            print('Model saved (best Jaccard index (IoU))')\n",
    "            \n",
    "            \n",
    "        ### LEARNING RATE MODIFICATION\n",
    "        # drop learning rate\n",
    "        if epoch == EPOCHS_DROP:\n",
    "            optimizer.param_groups[0]['lr'] = LR_DROP\n",
    "            print('\\nLearning rate dropped: {}'.format(LR_DROP))\n",
    "\n",
    "            \n",
    "    fold_end = time.time()\n",
    "    print('\\nFold {} training: Finished'.format(fold))\n",
    "    print('Best Dice/F1 score @ epoch: {:.4f} @ {}'.format(max_score_dice, best_epoch_dice))\n",
    "    print('Best Jaccard/IoU score @ epoch: {:.4f} @ {}'.format(max_score_jaccard, best_epoch_jaccard))\n",
    "    print('Duration: ~{:.0f} min'.format((fold_end - fold_start)/60))\n",
    "\n",
    "    \n",
    "cv_end = time.time()\n",
    "print('\\n', '-'*80, sep='')\n",
    "print('\\n', '{}-fold cross-validation: Finished'.format(FOLDS))\n",
    "print('Duration: ~{:.0f} min'.format((cv_end - cv_start)/60))\n",
    "\n",
    "\n",
    "# write simple log\n",
    "with open(path.join(PATH_LOG, 'log.txt'), 'w') as file:\n",
    "    file.write('{}'.format(str(txt_log)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize validation log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r', 'g', 'b', 'y', 'k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 5)\n",
    "fig.set_dpi(80)\n",
    "\n",
    "ax.set(xlabel='Epoch', ylabel='Dice/F1 loss', title='Dice/F1 loss over epochs')\n",
    "ax.grid()\n",
    "\n",
    "epochs = np.arange(0, EPOCHS, 1)\n",
    "for i in range(1, FOLDS+1):\n",
    "    fold = list(filter(lambda m: m['fold'] == i, txt_log))\n",
    "    losses = np.array([d[\"dice_loss\"] for d in fold])\n",
    "    losses = [float(l) for l in losses] # float conversion\n",
    "    ax.plot(epochs+1, losses, colors[i-1], label = 'Fold {}'.format(i))\n",
    "legend = ax.legend(loc='upper right', shadow=True, fontsize='x-large')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(PATH_RUN, \"dice_loss.png\"))\n",
    "fig.savefig(os.path.join(PATH_RUN, \"dice_loss.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 5)\n",
    "fig.set_dpi(80)\n",
    "\n",
    "ax.set(xlabel='Epoch', ylabel='Dice/F1 score', title='Dice/F1 scores over epochs')\n",
    "ax.grid()\n",
    "\n",
    "epochs = np.arange(0, EPOCHS, 1)\n",
    "for i in range(1, FOLDS+1):\n",
    "    fold = list(filter(lambda m: m['fold'] == i, txt_log))\n",
    "    losses = np.array([d[\"fscore\"] for d in fold])\n",
    "    losses = [float(l) for l in losses] # float conversion\n",
    "    ax.plot(epochs+1, losses, colors[i-1], label = 'Fold {}'.format(i))\n",
    "legend = ax.legend(loc='lower right', shadow=True, fontsize='x-large')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(PATH_RUN, \"f1_score.png\"))\n",
    "fig.savefig(os.path.join(PATH_RUN, \"f1_score.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 5)\n",
    "fig.set_dpi(80)\n",
    "\n",
    "ax.set(xlabel='Epoch', ylabel='Jaccard/IoU score', title='Jaccard/IoU scores over epochs')\n",
    "ax.grid()\n",
    "\n",
    "epochs = np.arange(0, EPOCHS, 1)\n",
    "for i in range(1, FOLDS+1):\n",
    "    fold = list(filter(lambda m: m['fold'] == i, txt_log))\n",
    "    losses = np.array([d[\"iou_score\"] for d in fold])\n",
    "    losses = [float(l) for l in losses] # float conversion\n",
    "    ax.plot(epochs+1, losses, colors[i-1], label = 'Fold {}'.format(i))\n",
    "legend = ax.legend(loc='lower right', shadow=True, fontsize='x-large')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(PATH_RUN, \"iou_score.png\"))\n",
    "fig.savefig(os.path.join(PATH_RUN, \"iou_score.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text output for sanity checks\n",
    "#train_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}-fold cross-validation model test: Started\".format(FOLDS))\n",
    "print(\"\\n--------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "\n",
    "test_log = list()\n",
    "for f in range(1, FOLDS+1):\n",
    "    \n",
    "    # load saved best fold model\n",
    "    test_image_dir, test_label_dir = PATH_VAL_IMAGES.format(f), PATH_VAL_LABELS.format(f)\n",
    "    best_model = torch.load(os.path.join(PATH_RUNS, RUN_NAME, 'best_model_fold{}.pth'.format(f)))\n",
    "\n",
    "    # create test dataset and loader\n",
    "    test_dataset = Dataset(\n",
    "        test_image_dir, test_label_dir, \n",
    "        augmentation=get_validation_augmentation(), \n",
    "        preprocessing=get_preprocessing(preprocessing_fn),\n",
    "        classes=CLASSES,\n",
    "    )\n",
    "    test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "    # evaluate model on test set\n",
    "    test_epoch = smp.utils.train.ValidEpoch(model=best_model, loss=loss, metrics=metrics, device=DEVICE)\n",
    "    logs = test_epoch.run(test_dataloader)\n",
    "    \n",
    "    # log test\n",
    "    test_log.append({\n",
    "        'fold': f, \n",
    "        'dice_loss': '{:.4f}'.format(logs['dice_loss']), \n",
    "        'fscore': '{:.4f}'.format(logs['fscore']),\n",
    "        'iou_score': '{:.4f}'.format(logs['iou_score'])\n",
    "    })\n",
    "\n",
    "print(\"\\n--------------------------------------------------------------------------------\")\n",
    "print(\"\\n{}-fold cross-validation: Finished\".format(FOLDS))\n",
    "\n",
    "\n",
    "with open('./test_log.txt', 'w') as f:\n",
    "    for item in test_log:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text output for sanity checks\n",
    "#test_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset with transformations for prediction\n",
    "test_dataset = Dataset(\n",
    "    PATH_VAL_IMAGES.format('1'), PATH_VAL_LABELS.format('1'), \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "# test dataset without transformations for image visualization\n",
    "test_dataset_vis = Dataset(\n",
    "    PATH_VAL_IMAGES.format('1'), PATH_VAL_LABELS.format('1'), #test_image_dir, test_label_dir, \n",
    "    classes=CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    n = np.random.choice(len(test_dataset))\n",
    "    \n",
    "    image_vis = test_dataset_vis[n][0].astype('uint8')\n",
    "    image, gt_mask = test_dataset[n]\n",
    "    \n",
    "    gt_mask = gt_mask.squeeze()\n",
    "    \n",
    "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "    pr_mask = best_model.predict(x_tensor)\n",
    "    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n",
    "        \n",
    "    visualize(\n",
    "        image=image_vis, \n",
    "        ground_truth_mask=gt_mask, \n",
    "        predicted_mask=pr_mask\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
