{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required libs\n",
    "#!pip install -U segmentation-models-pytorch albumentations --user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import path\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root dir\n",
    "PATH_ROOT = 'root_dir'\n",
    "\n",
    "# dataset dirs\n",
    "DATASET = 'dataset_name'\n",
    "PATH_DATASET = path.join(PATH_ROOT, 'datasets/enriched/', DATASET)\n",
    "PATH_TRAIN_IMAGES = path.join(PATH_DATASET, 'train/images/')\n",
    "PATH_TRAIN_LABELS = path.join(PATH_DATASET, 'train/labels_thresh128/')\n",
    "PATH_VAL_IMAGES = PATH_TRAIN_IMAGES\n",
    "PATH_VAL_LABELS = PATH_TRAIN_LABELS\n",
    "print(PATH_DATASET)\n",
    "\n",
    "n_ti, n_tl = len(os.listdir(PATH_TRAIN_IMAGES)), len(os.listdir(PATH_TRAIN_LABELS))\n",
    "print('train ', n_ti, '/', n_tl, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyworded visualization: title_name_1=image1, title_name_2=image2, ...\n",
    "def visualize(**images):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.title(' '.join(name.split('_')).title()) # keyword as title\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "# non-keyworded images: image1, image2, ...\n",
    "def visualize_grid(*images):\n",
    "    n, cols = len(images), 4\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    gs = gridspec.GridSpec(rows, cols)\n",
    "    fig = plt.figure(figsize=(16, 4*rows))\n",
    "    fig.tight_layout()\n",
    "    for i in range(n):\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        ax.imshow(images[i])\n",
    "        ax.axis('off')    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes/intensities\n",
    "CLASSES = [\n",
    "    'background',\n",
    "    'wound'\n",
    "]\n",
    "\n",
    "for i in range(len(CLASSES)):\n",
    "    print('value ', i, ':\\t', CLASSES[i], sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "\n",
    "    CLASSES = ['background', 'wound']\n",
    "    \n",
    "    def __init__(self, images_dir, masks_dir, classes=None, augmentation=None, preprocessing=None):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv.imread(self.images_fps[i])\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        mask = cv.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# inspect training data\n",
    "train_dataset = Dataset(PATH_TRAIN_IMAGES, PATH_TRAIN_LABELS, classes=['wound'])\n",
    "image, mask = train_dataset[1] # get some sample\n",
    "visualize(image=image, wound_mask=mask.squeeze())\n",
    "\n",
    "# save image height/width\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, _ = image.shape\n",
    "assert (IMAGE_HEIGHT % 32) + (IMAGE_WIDTH % 32) == 0, 'image height/width must be divisible by 32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION = 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        \n",
    "        # random crop (basic)\n",
    "        albu.RandomCrop(\n",
    "            height=352,\n",
    "            width=352,\n",
    "            always_apply=True\n",
    "        ),\n",
    "        \n",
    "        # geometry (basic)\n",
    "        albu.Flip(p=0.5),\n",
    "        albu.ShiftScaleRotate(p=0.5),\n",
    "        \n",
    "        # distortion, shuffling (heavy)\n",
    "        albu.OneOf([\n",
    "            albu.GridDistortion(p=1),            \n",
    "            albu.ElasticTransform(p=1),\n",
    "        ], p=0.5),      \n",
    "        \n",
    "        # contrast, brightness (basic)\n",
    "        albu.OneOf([\n",
    "            albu.CLAHE(p=1),\n",
    "            albu.RandomGamma(p=1),\n",
    "            albu.RandomBrightnessContrast(p=1),\n",
    "        ], p=0.5),\n",
    "\n",
    "        # blurring, sharpening (basic)\n",
    "        albu.OneOf([\n",
    "            albu.Sharpen(p=1),\n",
    "            albu.Blur(blur_limit=8, p=1),\n",
    "            albu.MotionBlur(blur_limit=8, p=1),\n",
    "        ], p=0.5),      \n",
    "        \n",
    "        # noise (basic)\n",
    "        albu.OneOf([\n",
    "            albu.GaussNoise(p=1),\n",
    "        ], p=0.5),\n",
    "               \n",
    "    ]\n",
    "    \n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    val_transform = [albu.PadIfNeeded(IMAGE_HEIGHT, IMAGE_WIDTH)]    \n",
    "    return albu.Compose(val_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):    \n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):    \n",
    "    _transform = [albu.Lambda(image=preprocessing_fn), albu.Lambda(image=to_tensor, mask=to_tensor)]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset with augmentation pipeline for training\n",
    "dataset = Dataset(\n",
    "    PATH_TRAIN_IMAGES, PATH_TRAIN_LABELS, \n",
    "    classes=CLASSES, augmentation=get_training_augmentation(),\n",
    ")\n",
    "\n",
    "# visualize exemplary sample augmentations\n",
    "visualize_grid(*[dataset[3103][0] for _ in range(16)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import time\n",
    "import os\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "MODEL = 'fpn' # TODO: currently hard-coded, fix\n",
    "ENCODER = 'se_resnext101_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda'\n",
    "CLASSES = ['wound'] # ['background', 'wound']\n",
    "\n",
    "# training parameters\n",
    "OPTIMIZER = 'adam' # TODO: currently hard-coded, fix\n",
    "LR_INIT = 0.0001\n",
    "LR_DROP_1 = 0.00001\n",
    "#LR_DROP_2 = 0.00001\n",
    "\n",
    "# batch size, epochs \n",
    "BATCH_SIZE = 24\n",
    "EPOCHS = 150\n",
    "EPOCHS_DROP_1 = 120 # LR_DROP after stated epoch (e.g., 25 -> reduced LR from epoch 26)\n",
    "#EPOCHS_DROP_2 = 225 # LR_DROP after stated epoch (e.g., 25 -> reduced LR from epoch 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run dir\n",
    "PATH_RUNS = path.join(PATH_ROOT, 'models/')\n",
    "\n",
    "# run name\n",
    "if LR_DROP_1 == None and EPOCHS_DROP_1 == None:\n",
    "    # no lr adjustments\n",
    "    RUN_NAME = 'training___{}___{}_{}_{}_{}___{}_lr{:.0e}___{}___bs{}_e{}'.format(\n",
    "        DATASET, MODEL, ENCODER, ENCODER_WEIGHTS, ACTIVATION, \n",
    "        OPTIMIZER, LR_INIT, AUGMENTATION, BATCH_SIZE, EPOCHS,\n",
    "    )\n",
    "else:\n",
    "    # lr adjustments\n",
    "    #RUN_NAME = 'training___{}___{}_{}_{}_{}___{}_lr{:.0e}_lrd1{:.0e}_lrd2{:.0e}___{}___bs{}_e{}_ed1{}_ed2{}___sameconf1'.format(\n",
    "    RUN_NAME = 'training___{}___{}_{}_{}_{}___{}_lr{:.0e}_lrd1{:.0e}___{}___bs{}_e{}_ed1{}___sameconf1'.format(\n",
    "        DATASET, MODEL, ENCODER, ENCODER_WEIGHTS, ACTIVATION, \n",
    "        #OPTIMIZER, LR_INIT, LR_DROP_1, LR_DROP_2, AUGMENTATION, BATCH_SIZE, EPOCHS, EPOCHS_DROP_1, EPOCHS_DROP_2\n",
    "        OPTIMIZER, LR_INIT, LR_DROP_1, AUGMENTATION, BATCH_SIZE, EPOCHS, EPOCHS_DROP_1\n",
    "    )\n",
    "print('dir:\\t', PATH_RUNS)\n",
    "print('run:\\t', RUN_NAME)\n",
    "print('path:\\t', path.join(PATH_RUNS, RUN_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create dirs\n",
    "PATH_RUN = path.join(PATH_RUNS, RUN_NAME)\n",
    "PATH_LOG = path.join(PATH_RUN, 'log')\n",
    "os.makedirs(PATH_LOG)\n",
    "\n",
    "# perform training\n",
    "print(\"Training: Started\")\n",
    "print('\\n', '-'*80, sep='')\n",
    "training_start = time.time()\n",
    "\n",
    "# tensorboard and text log\n",
    "tb_log = SummaryWriter(log_dir=PATH_LOG)\n",
    "txt_log = list()\n",
    "\n",
    "\n",
    "### MODEL\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.FPN(\n",
    "    encoder_name=ENCODER, encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=len(CLASSES), activation=ACTIVATION\n",
    ")\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "\n",
    "### DATASETS, LOADERS\n",
    "# create training and validation datasets and loaders\n",
    "train_dataset = Dataset(\n",
    "    PATH_TRAIN_IMAGES, PATH_TRAIN_LABELS,\n",
    "    augmentation=get_training_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "val_dataset = Dataset(\n",
    "    PATH_VAL_IMAGES, PATH_VAL_LABELS,\n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=24, prefetch_factor=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "    \n",
    "    \n",
    "### LOSS, SCORE, OPTIMIZER\n",
    "# create loss, score, and optimizer\n",
    "loss = smp.utils.losses.DiceLoss() # Dice/F1 loss\n",
    "metrics = [\n",
    "    smp.utils.metrics.Fscore(threshold=0.5), # Dice/F1 Score\n",
    "    smp.utils.metrics.IoU(threshold=0.5), # Jaccard/IoU score\n",
    "] \n",
    "optimizer = torch.optim.Adam([dict(params=model.parameters(), lr=LR_INIT)])\n",
    "\n",
    "\n",
    "### RUNNERS\n",
    "# create epoch runners (loop of iterating over dataloader's samples)\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, loss=loss, metrics=metrics, \n",
    "    optimizer=optimizer, device=DEVICE, verbose=True\n",
    ")\n",
    "val_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, loss=loss, metrics=metrics, \n",
    "    device=DEVICE, verbose=True\n",
    ")\n",
    "\n",
    "### TRAINING\n",
    "# train model\n",
    "max_score_dice = 0\n",
    "max_score_jaccard = 0\n",
    "best_epoch_dice = 0\n",
    "best_epoch_jaccard = 0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(epoch))\n",
    "    remaining = EPOCHS - epoch # remaining epochs\n",
    "    \n",
    "    # run epoch (only evaluate every n-th epoch, and last epochs)\n",
    "    train_logs = train_epoch.run(train_loader)    \n",
    "    if (epoch == 1) or (epoch % 50 == 0) or (remaining < 1):\n",
    "        val_logs = val_epoch.run(val_loader)\n",
    "\n",
    "\n",
    "    ### LOGGING\n",
    "    # dice/f1 loss\n",
    "    tb_log.add_scalar('train/Dice loss (F1)', train_logs['dice_loss'], epoch)\n",
    "    tb_log.add_scalar('val/Dice loss (F1)', val_logs['dice_loss'], epoch)\n",
    "\n",
    "    # dice/f1 score\n",
    "    tb_log.add_scalar(\"train/Dice score (F1)\", train_logs['fscore'], epoch)\n",
    "    tb_log.add_scalar(\"val/Dice score (F1)\", val_logs['fscore'], epoch)\n",
    "\n",
    "    # jaccard/iou score\n",
    "    tb_log.add_scalar('train/Jaccard index (IoU)', train_logs['iou_score'], epoch)\n",
    "    tb_log.add_scalar('val/Jaccard index (IoU)', val_logs['iou_score'], epoch)\n",
    "\n",
    "    txt_log.append({\n",
    "        'epoch': epoch, \n",
    "        'dice_loss': val_logs['dice_loss'],\n",
    "        'fscore': val_logs['fscore'],\n",
    "        'iou_score': val_logs['iou_score'],\n",
    "    })\n",
    "\n",
    "\n",
    "    ### EVALUATION\n",
    "    # save epoch if better dice/f1\n",
    "    if max_score_dice < val_logs['fscore']:\n",
    "        max_score_dice = val_logs['fscore']\n",
    "        best_epoch_dice = epoch\n",
    "        torch.save(model, path.join(PATH_RUN, './best_model_dice.pth'))\n",
    "        with open(os.path.join(PATH_LOG, 'best_model_dice.txt'), 'w') as file:\n",
    "            file.write('Best epoch: {}, Dice/F1 score (val): {:.4f}'.format(epoch, max_score_dice))\n",
    "        print('Model saved (best Dice/F1 score)')\n",
    "\n",
    "    # save epoch if better jaccard/iou\n",
    "    if max_score_jaccard < val_logs['iou_score']:\n",
    "        max_score_jaccard = val_logs['iou_score']\n",
    "        best_epoch_jaccard = epoch\n",
    "        torch.save(model, path.join(PATH_RUN, './best_model_jaccard.pth'))\n",
    "        with open(os.path.join(PATH_LOG, 'best_model_jaccard.txt'), 'w') as file:\n",
    "            file.write('Best epoch: {}, Jaccard/IoU score (val): {:.4f}'.format(epoch, max_score_jaccard))\n",
    "        print('Model saved (best Jaccard/IoU score)')\n",
    "    \n",
    "    # save last five epochs\n",
    "    if remaining < 5:\n",
    "        \n",
    "        # save range of last epochs\n",
    "        torch.save(model, path.join(PATH_RUN, 'last_model-{}.pth'.format(remaining)))\n",
    "        with open(path.join(PATH_LOG, 'last_model-{}.txt'.format(remaining)), 'w') as file:\n",
    "            file.write('Last epoch: {}, IoU (val): {:.4f}'.format(epoch, val_logs['iou_score']))\n",
    "        print('One of the last epochs saved!')\n",
    "        \n",
    "        # save last epoch under different name\n",
    "        if epoch == EPOCHS:\n",
    "            torch.save(model, path.join(PATH_RUN, './last_model.pth'))\n",
    "            with open(path.join(PATH_LOG, 'last_model.txt'), 'w') as file:\n",
    "                file.write('Last epoch: {}, IoU (val): {:.4f}'.format(epoch, val_logs['iou_score']))\n",
    "            print('Last model saved!')\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### LEARNING RATE MODIFICATION\n",
    "    # drop learning rate\n",
    "    if epoch == EPOCHS_DROP_1:\n",
    "        optimizer.param_groups[0]['lr'] = LR_DROP_1\n",
    "        print('\\nLearning rate dropped: {}'.format(LR_DROP_1))\n",
    "\n",
    "    #if epoch == EPOCHS_DROP_2:\n",
    "    #    optimizer.param_groups[0]['lr'] = LR_DROP_2\n",
    "    #    print('\\nLearning rate dropped: {}'.format(LR_DROP_2))\n",
    "    \n",
    "\n",
    "training_end = time.time()\n",
    "print('\\n', '-'*80, sep='')\n",
    "print(\"\\nTraining: Finished\")\n",
    "print(\"Duration: ~{:.0f} min\".format((training_end - training_start)/60))\n",
    "\n",
    "\n",
    "# write simple log\n",
    "with open(path.join(PATH_LOG, 'log.txt'), 'w') as file:\n",
    "    file.write('{}'.format(str(txt_log)))\n",
    "    print('Text log written to:', PATH_LOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize validation log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 5)\n",
    "fig.set_dpi(80)\n",
    "\n",
    "ax.set(xlabel='Epoch', ylabel='Dice/F1 loss', title='Dice/F1 loss over epochs')\n",
    "ax.grid()\n",
    "\n",
    "epochs = np.arange(0, EPOCHS, 1)\n",
    "losses = np.array([d[\"dice_loss\"] for d in txt_log])\n",
    "losses = [float(l) for l in losses] # float conversion\n",
    "ax.plot(epochs+1, losses, colors[0], label = 'Training')\n",
    "legend = ax.legend(loc='upper right', shadow=True, fontsize='x-large')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(PATH_RUN, \"dice_loss.png\"))\n",
    "fig.savefig(os.path.join(PATH_RUN, \"dice_loss.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 5)\n",
    "fig.set_dpi(80)\n",
    "\n",
    "ax.set(xlabel='Epoch', ylabel='IoU/Jaccard score', title='IoU/Jaccard scores over epochs')\n",
    "ax.grid()\n",
    "\n",
    "epochs = np.arange(0, EPOCHS, 1)\n",
    "losses = np.array([d[\"iou_score\"] for d in txt_log])\n",
    "losses = [float(l) for l in losses] # float conversion\n",
    "ax.plot(epochs+1, losses, colors[0], label = 'Training')\n",
    "legend = ax.legend(loc='lower right', shadow=True, fontsize='x-large')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(PATH_RUN, \"iou_score.png\"))\n",
    "fig.savefig(os.path.join(PATH_RUN, \"iou_score.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text output for sanity checks\n",
    "#train_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last model test: Started\")\n",
    "print(\"\\n--------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "test_log = list()\n",
    "\n",
    "# load saved best fold model\n",
    "best_model = torch.load(os.path.join(WORKING_DIR, RUN_NAME, 'last_model.pth'))\n",
    "\n",
    "# create test dataset and loader\n",
    "test_dataset = Dataset(\n",
    "    test_image_dir, test_label_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "# evaluate model on test set\n",
    "test_epoch = smp.utils.train.ValidEpoch(model=best_model, loss=loss, metrics=metrics, device=DEVICE)\n",
    "logs = test_epoch.run(test_dataloader)\n",
    "\n",
    "# log test\n",
    "test_log.append({\n",
    "    'dice_loss': '{:.4f}'.format(logs['dice_loss']), \n",
    "    'iou_score': '{:.4f}'.format(logs['iou_score'])\n",
    "})\n",
    "\n",
    "print(\"\\n--------------------------------------------------------------------------------\")\n",
    "print(\"Last model test: Finished\")\n",
    "\n",
    "\n",
    "with open('./test_log.txt', 'w') as f:\n",
    "    for item in test_log:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text output for sanity checks\n",
    "#test_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset without transformations for image visualization\n",
    "test_dataset_vis = Dataset(\n",
    "    test_image_dir, test_label_dir, \n",
    "    classes=CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    n = np.random.choice(len(test_dataset))\n",
    "    \n",
    "    image_vis = test_dataset_vis[n][0].astype('uint8')\n",
    "    image, gt_mask = test_dataset[n]\n",
    "    \n",
    "    gt_mask = gt_mask.squeeze()\n",
    "    \n",
    "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "    pr_mask = best_model.predict(x_tensor)\n",
    "    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n",
    "        \n",
    "    visualize(\n",
    "        image=image_vis, \n",
    "        ground_truth_mask=gt_mask, \n",
    "        predicted_mask=pr_mask\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
