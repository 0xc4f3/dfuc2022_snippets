{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from os import path\n",
    "from glob import glob\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "def visualize(**images):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# non-keyworded images: image1, image2, ...\n",
    "def visualize_grid(*images):\n",
    "    n, cols = len(images), 4\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    gs = gridspec.GridSpec(rows, cols)\n",
    "    fig = plt.figure(figsize=(16, 4*rows))\n",
    "    fig.tight_layout()\n",
    "    for i in range(n):\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        ax.imshow(images[i])\n",
    "        ax.axis('off')    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /raid/bruengel/Wound/projects/dfuc2022/predictions/baseline/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PREDICTIONS = 'root_dir'\n",
    "DIR_IMAGES = 'image_dir'\n",
    "\n",
    "NAME_PREDICTION = 'prediction_dir'\n",
    "NAME_DATASET = 'baseline'\n",
    "NAME_PART = 'test'\n",
    "NAME_POSTPROC = 'pp_geq01_fill_open2'\n",
    "DIR_PREDICTIONS_IN = path.join(DIR_PREDICTIONS, NAME_PREDICTION)\n",
    "DIR_PREDICTIONS_OUT = path.join(DIR_PREDICTIONS, NAME_PREDICTION + '__' + NAME_POSTPROC)\n",
    "print('in:', DIR_PREDICTIONS_IN)\n",
    "print('out:', DIR_PREDICTIONS_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls $DIR_PREDICTIONS_IN/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view samples\n",
    "samples = range(140, 170, 1)\n",
    "for sample in samples:\n",
    "    fi = sorted(glob(path.join(DIR_IMAGES, \"*.png\")))[sample]\n",
    "    fp = sorted(glob(path.join(DIR_PREDICTIONS_IN, \"*.png\")))[sample]\n",
    "    print('\\nfile:', fp)\n",
    "\n",
    "    # original image, prediction, extract\n",
    "    image = cv.imread(fi, cv.IMREAD_COLOR) \n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    pred_in = cv.imread(fp, cv.IMREAD_GRAYSCALE)\n",
    "    extract = cv.bitwise_and(image, image, mask=pred_in*255)\n",
    "    visualize(original_image=image, extract=extract)\n",
    "    #visualize(original_image=image, predicted_mask=pred_in, extract=extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# containers\n",
    "rows_file = []\n",
    "rows_inst = []\n",
    "\n",
    "# process all \n",
    "files = sorted(glob(path.join(DIR_PREDICTIONS_IN, \"*.png\")))\n",
    "for f in files:\n",
    "    \n",
    "    # read as rgb image\n",
    "    mask_in = cv.imread(f, cv.IMREAD_COLOR) \n",
    "    mask_in = cv.cvtColor(mask_in, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    # append file row\n",
    "    rows_file.append([path.basename(f), mask_in.shape[1], mask_in.shape[0]])\n",
    "    \n",
    "    # set as binary mask\n",
    "    gray = cv.cvtColor(mask_in, cv.COLOR_BGR2GRAY);\n",
    "    mask = cv.inRange(gray, 1, 255);\n",
    "\n",
    "    # detect contours and analyze\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE);\n",
    "    instance = 0\n",
    "    for c in contours:\n",
    "        instance += 1\n",
    "\n",
    "        # area, arc length\n",
    "        area = np.int0(cv.contourArea(c))\n",
    "        arcl = cv.arcLength(c, True)\n",
    "\n",
    "        # rectangle (bbox)\n",
    "        x, y, w, h = cv.boundingRect(c)    \n",
    "        bbox_min, bbox_max = min(w, h), max(w, h)\n",
    "\n",
    "        # min area rotated rectangle (rbox)\n",
    "        # sloppy opencv definitions lead to slightly inconsistent results between boundingRect and minAreaRect\n",
    "        # https://stackoverflow.com/questions/69911364/whats-the-difference-in-results-of-cvboundingrect-and-cvminarearect\n",
    "        rect = cv.minAreaRect(c)\n",
    "        rbox = np.int0(cv.boxPoints(rect))\n",
    "        a, b = cv.norm(rbox[0], rbox[1]), cv.norm(rbox[1], rbox[2])\n",
    "        rbox_min, rbox_max = min(a, b), max(a, b)\n",
    "        \n",
    "        # append instance row\n",
    "        rows_inst.append([path.basename(f), instance, area, arcl, bbox_min, bbox_max, rbox_min, rbox_max])\n",
    "    \n",
    "    # exceptional case of no contour\n",
    "    if instance == 0:\n",
    "        rows_inst.append([path.basename(f), 0, None, None, None, None, None, None])\n",
    "\n",
    "# create dfs\n",
    "df_file = pd.DataFrame(rows_file, columns=[\n",
    "    'file', 'width', 'height'])\n",
    "df_inst = pd.DataFrame(rows_inst, columns=[\n",
    "    'file', 'inst', 'area', 'arc_len', 'bbox_min', 'bbox_max', 'rbox_min', 'rbox_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extension of instances data frame\n",
    "df_inst = df_file.join(df_inst.set_index('file'), on = 'file')\n",
    "\n",
    "# further area features\n",
    "area_sqrt = np.sqrt(df_inst['area'])\n",
    "df_inst.insert (5, 'area_sqrt', area_sqrt) # \n",
    "area_perc = df_inst['area'] / (df_inst['width'] * df_inst['height']) * 100\n",
    "df_inst.insert (6, 'area_perc', area_perc) # area percentage\n",
    "\n",
    "# further box features\n",
    "bbox_ratio = df_inst['bbox_max'] / df_inst['bbox_min']\n",
    "df_inst.insert (10, 'bbox_ratio', bbox_ratio) # bbox side ratio\n",
    "rbox_ratio = df_inst['rbox_max'] / df_inst['rbox_min']\n",
    "df_inst.insert (13, 'rbox_ratio', rbox_ratio) # rbox side ratio\n",
    "\n",
    "# remove file-related cols\n",
    "df_inst = df_inst.drop(columns = ['width', 'height'])\n",
    "\n",
    "# basic description\n",
    "df_inst.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances per image\n",
    "fig = px.histogram(df_inst, x=\"inst\", marginal=\"box\")\n",
    "fig.update_traces(xbins = dict(start=0.0, size=1.0), selector=dict(type='histogram'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance area (percent)\n",
    "fig = px.histogram(df_inst, x=\"area_perc\", marginal=\"box\", hover_data=df_inst.columns)\n",
    "fig.update_traces(xbins = dict(start=0.0, size=0.05), selector=dict(type='histogram'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_AREA_PERC_TO_KEEP = 0.02 # min percentage instance area to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(pred_in):\n",
    "    \n",
    "    h, w = pred_in.shape\n",
    "    pred_out = pred_in.copy()    \n",
    "    \n",
    "    ###\n",
    "    # step 1: instance area filtering for more than one instance, potential filling\n",
    "    contours, _ = cv.findContours(pred_in, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE);\n",
    "    contours = sorted(contours, key=cv.contourArea)\n",
    "    instances = len(contours)\n",
    "    print(instances, 'instances')\n",
    "    for c in contours:  \n",
    "        area_perc = (cv.contourArea(c) / (w * h)) * 100 # area percent\n",
    "        \n",
    "        # blacken if too small and more than one instance in prediction\n",
    "        if instances > 1 and area_perc < MIN_AREA_PERC_TO_KEEP:\n",
    "            cv.drawContours(pred_out, [c], contourIdx=-1, color=0, thickness=-1, lineType=cv.LINE_AA)\n",
    "            print(area_perc, 'removed')\n",
    "            continue # skip rest to avoid restoring of removed contours\n",
    "            \n",
    "        # skip if just one instance or large enough\n",
    "        else:\n",
    "            print(area_perc, 'only instance, filtering skipped')\n",
    "\n",
    "        # fill potential holes in masks\n",
    "        cv.drawContours(pred_out, [c], contourIdx=-1, color=1, thickness=-1, lineType=cv.LINE_AA)\n",
    "        print(area_perc, 'potential holes closed')\n",
    "        \n",
    "    ###\n",
    "    # step 2: mild opening to remove contour removal artifacts\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (2, 2))\n",
    "    pred_out = cv.morphologyEx(pred_out, cv.MORPH_OPEN, kernel)\n",
    "    print('mildly opened')\n",
    "    \n",
    "    return pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check effects on subset\n",
    "samples = range(200, 250, 1)\n",
    "for sample in samples:\n",
    "    fi = sorted(glob(path.join(DIR_IMAGES, \"*.png\")))[sample]\n",
    "    fp = sorted(glob(path.join(DIR_PREDICTIONS_IN, \"*.png\")))[sample]\n",
    "    print('\\nfile:', fp)\n",
    "\n",
    "    # original image, prediction, extract\n",
    "    image = cv.imread(fi, cv.IMREAD_COLOR) \n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    pred_in = cv.imread(fp, cv.IMREAD_GRAYSCALE)\n",
    "    extract_in = cv.bitwise_and(image, image, mask=pred_in*255)\n",
    "    \n",
    "    # post-processed prediction, extract\n",
    "    pred_out = postprocessing(pred_in)\n",
    "    extract_out = cv.bitwise_and(image, image, mask=pred_out*255)\n",
    "    \n",
    "    visualize(image=image, prediction_in=pred_in, prediction_out=pred_out)\n",
    "    visualize(image=image, extract_in=extract_in, extract_out=extract_out)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dir if not existing\n",
    "if not path.isdir(DIR_PREDICTIONS_OUT):\n",
    "    os.makedirs(DIR_PREDICTIONS_OUT)\n",
    "\n",
    "# post-process predictions\n",
    "print('out:', DIR_PREDICTIONS_OUT)\n",
    "files = sorted(glob(path.join(DIR_PREDICTIONS_IN, \"*.png\")))\n",
    "for f in files:\n",
    "    print('\\nfile:', f)\n",
    "    \n",
    "    # process\n",
    "    pred_in = cv.imread(f, cv.IMREAD_GRAYSCALE)\n",
    "    pred_out = postprocessing(pred_in)\n",
    "    \n",
    "    # write\n",
    "    cv.imwrite(path.join(DIR_PREDICTIONS_OUT, path.basename(f)), pred_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
